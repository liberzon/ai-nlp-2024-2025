{
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install -y spacy",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:01:22.367867Z",
     "start_time": "2024-12-26T15:01:22.243069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: conda: command not found\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "!pip install -y spacy-lookups-data",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:01:22.491748Z",
     "start_time": "2024-12-26T15:01:22.372353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: conda: command not found\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:01:23.967846Z",
     "start_time": "2024-12-26T15:01:22.577534Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:01:23.974080Z",
     "start_time": "2024-12-26T15:01:23.972183Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "#A list of words to be stemmed\n",
    "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\"railroad\",\"moonlight\",\"football\"]\n",
    "print(\"{0:20}{1:20}\".format(\"Word\", \"Lemmatizer\"))\n",
    "for word in word_list:\n",
    "    print(\"{0:20}{1:20}\".format(word, lemmatizer.lemmatize(word)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:01:25.424007Z",
     "start_time": "2024-12-26T15:01:23.979066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemmatizer          \n",
      "friend              friend              \n",
      "friendship          friendship          \n",
      "friends             friend              \n",
      "friendships         friendship          \n",
      "stabil              stabil              \n",
      "destabilize         destabilize         \n",
      "misunderstanding    misunderstanding    \n",
      "railroad            railroad            \n",
      "moonlight           moonlight           \n",
      "football            football            \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"rocks:\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora:\", lemmatizer.lemmatize(\"corpora\"))\n",
    "print(\"indices:\", lemmatizer.lemmatize(\"indices\"))\n",
    "print(\"better:\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n",
    "print(\"better:\", lemmatizer.lemmatize(\"better\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:01:25.432141Z",
     "start_time": "2024-12-26T15:01:25.429572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks: rock\n",
      "corpora: corpus\n",
      "indices: index\n",
      "better: good\n",
      "better: better\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scikit-Learn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "\n",
    "bow_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(),\n",
    "                                strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:01:25.439715Z",
     "start_time": "2024-12-26T15:01:25.437064Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spacy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sample_text = \"Apple is looking at buying U.K. startup for $1 billion\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:01:25.448641Z",
     "start_time": "2024-12-26T15:01:25.446309Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokens = nlp(sample_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:01:25.765446Z",
     "start_time": "2024-12-26T15:01:25.454196Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "nlp.pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:01:25.776198Z",
     "start_time": "2024-12-26T15:01:25.772970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x128e5ebd0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x128e5eab0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x128e66ce0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x12fa6e2d0>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x12fa672d0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x12f10c190>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "token_list = []\n",
    "for token in tokens:\n",
    "    token_list.append(token.text)\n",
    "token_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:01:25.784680Z",
     "start_time": "2024-12-26T15:01:25.782013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple',\n",
       " 'is',\n",
       " 'looking',\n",
       " 'at',\n",
       " 'buying',\n",
       " 'U.K.',\n",
       " 'startup',\n",
       " 'for',\n",
       " '$',\n",
       " '1',\n",
       " 'billion']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "lemma_list = []\n",
    "for token in tokens:\n",
    "    lemma_list.append(token.lemma_)\n",
    "lemma_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:01:25.793041Z",
     "start_time": "2024-12-26T15:01:25.790738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple',\n",
       " 'be',\n",
       " 'look',\n",
       " 'at',\n",
       " 'buy',\n",
       " 'U.K.',\n",
       " 'startup',\n",
       " 'for',\n",
       " '$',\n",
       " '1',\n",
       " 'billion']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
