{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.771071Z",
     "start_time": "2024-12-26T15:00:03.768618Z"
    }
   },
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.776267Z",
     "start_time": "2024-12-26T15:00:03.774378Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "Additional stemmers can be found <a href=\"https://www.nltk.org/api/nltk.stem.html\">here</a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.784300Z",
     "start_time": "2024-12-26T15:00:03.781724Z"
    }
   },
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "#A list of words to be stemmed\n",
    "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\"railroad\",\"moonlight\",\"football\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.793304Z",
     "start_time": "2024-12-26T15:00:03.790339Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"lancaster Stemmer\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.854734Z",
     "start_time": "2024-12-26T15:00:03.852240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Porter Stemmer      lancaster Stemmer   \n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "for word in word_list:\n",
    "    print(\"{0:20}{1:20}{2:20}\".format(word,porter.stem(word),lancaster.stem(word)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.878690Z",
     "start_time": "2024-12-26T15:00:03.874194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friend              friend              friend              \n",
      "friendship          friendship          friend              \n",
      "friends             friend              friend              \n",
      "friendships         friendship          friend              \n",
      "stabil              stabil              stabl               \n",
      "destabilize         destabil            dest                \n",
      "misunderstanding    misunderstand       misunderstand       \n",
      "railroad            railroad            railroad            \n",
      "moonlight           moonlight           moonlight           \n",
      "football            footbal             footbal             \n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "sentence=\"Pythoners are very intelligent and work very pythonly and now they are pythoning their way to success.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.894522Z",
     "start_time": "2024-12-26T15:00:03.892120Z"
    }
   },
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "print(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.906359Z",
     "start_time": "2024-12-26T15:00:03.903797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythoners are very intelligent and work very pythonly and now they are pythoning their way to success.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "def stem_sentence(input_sentence):\n",
    "    token_words = word_tokenize(input_sentence)\n",
    "    stemmed_sentence = []\n",
    "    stemmed_sentence_including_sep = []\n",
    "    for word in token_words:\n",
    "        stemmed_sentence.append(porter.stem(word))\n",
    "        stemmed_sentence_including_sep.append(porter.stem(word))\n",
    "        stemmed_sentence_including_sep.append(\" \")\n",
    "    return \"\".join(stemmed_sentence_including_sep), stemmed_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.920235Z",
     "start_time": "2024-12-26T15:00:03.917718Z"
    }
   },
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": [
    "stemmed, stemmed_list = stem_sentence(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.936974Z",
     "start_time": "2024-12-26T15:00:03.925545Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m stemmed, stemmed_list \u001B[38;5;241m=\u001B[39m \u001B[43mstem_sentence\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[29], line 2\u001B[0m, in \u001B[0;36mstem_sentence\u001B[0;34m(input_sentence)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstem_sentence\u001B[39m(input_sentence):\n\u001B[0;32m----> 2\u001B[0m     token_words \u001B[38;5;241m=\u001B[39m \u001B[43mword_tokenize\u001B[49m(input_sentence)\n\u001B[1;32m      3\u001B[0m     stemmed_sentence \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      4\u001B[0m     stemmed_sentence_including_sep \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mNameError\u001B[0m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python are veri intellig and work veri pythonli and now they are python their way to success . \n"
     ]
    }
   ],
   "source": [
    "print(stemmed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.941814Z",
     "start_time": "2024-12-19T13:23:52.584138Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'are', 'veri', 'intellig', 'and', 'work', 'veri', 'pythonli', 'and', 'now', 'they', 'are', 'python', 'their', 'way', 'to', 'success', '.']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.942520Z",
     "start_time": "2024-12-19T13:23:53.509504Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "doc1 = 'This pasta is very tasty and affordable.'\n",
    "doc2 = 'This pasta is not tasty and is affordable.'\n",
    "doc3 = 'This pasta is delicious and cheap.'\n",
    "doc4 = 'Pasta is tasty and pasta tastes good.'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.942769Z",
     "start_time": "2024-12-19T13:23:54.443191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = [doc1, doc2, doc3, doc4], columns=['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.951683Z",
     "start_time": "2024-12-19T13:23:55.086303Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         text\n0    This pasta is very tasty and affordable.\n1  This pasta is not tasty and is affordable.\n2          This pasta is delicious and cheap.\n3       Pasta is tasty and pasta tastes good.",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This pasta is very tasty and affordable.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This pasta is not tasty and is affordable.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>This pasta is delicious and cheap.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pasta is tasty and pasta tastes good.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.954046Z",
     "start_time": "2024-12-19T13:23:55.638488Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def my_tokenizer_and_stemmer(input_text):\n",
    "    return stem_sentence(input_text)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.955162Z",
     "start_time": "2024-12-19T13:23:56.746911Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "df['tokens'] = df['text'].apply(lambda x: my_tokenizer_and_stemmer(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.955489Z",
     "start_time": "2024-12-19T13:23:57.287065Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         text  \\\n0    This pasta is very tasty and affordable.   \n1  This pasta is not tasty and is affordable.   \n2          This pasta is delicious and cheap.   \n3       Pasta is tasty and pasta tastes good.   \n\n                                             tokens  \n0     [thi, pasta, is, veri, tasti, and, afford, .]  \n1  [thi, pasta, is, not, tasti, and, is, afford, .]  \n2           [thi, pasta, is, delici, and, cheap, .]  \n3     [pasta, is, tasti, and, pasta, tast, good, .]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This pasta is very tasty and affordable.</td>\n      <td>[thi, pasta, is, veri, tasti, and, afford, .]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This pasta is not tasty and is affordable.</td>\n      <td>[thi, pasta, is, not, tasti, and, is, afford, .]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>This pasta is delicious and cheap.</td>\n      <td>[thi, pasta, is, delici, and, cheap, .]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pasta is tasty and pasta tastes good.</td>\n      <td>[pasta, is, tasti, and, pasta, tast, good, .]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.955594Z",
     "start_time": "2024-12-19T13:23:58.060610Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T15:00:03.963098Z",
     "start_time": "2024-02-12T21:44:50.212324Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
