{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:14.869104Z",
     "start_time": "2024-11-20T14:43:14.569684Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sortedcontainers import SortedSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "doc1 = 'This pasta is very tasty and affordable.'\n",
    "doc2 = 'This pasta is not tasty and is affordable.'\n",
    "doc3 = 'This pasta is delicious and cheap.'\n",
    "doc4 = 'Pasta is tasty and pasta tastes good.'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:14.872121Z",
     "start_time": "2024-11-20T14:43:14.870060Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# This line defines a regular expression pattern tokenizer_re. The pattern [^a-zA-Z0-9] is used to match any character that is not a lowercase letter (a-z), an uppercase letter (A-Z), or a digit (0-9). The r before the string indicates a raw string in Python, which tells Python to interpret the backslashes in the string as literal characters and not as escape characters.\n",
    "tokenizer_re = r\"[^a-zA-Z0-9]\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:14.875481Z",
     "start_time": "2024-11-20T14:43:14.872879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Split the sentence to a list of the words contained in the sentence (split by spaces between the words)\n",
    "\n",
    "# This line imports Python's built-in re module, which provides support for regular expressions.\n",
    "import re\n",
    "\n",
    "def tokenize(doc: str) -> list():\n",
    "    # שלב 1: נורמליזציה לאותיות קטנות\n",
    "    lowercased = doc.lower()\n",
    "\n",
    "    # שלב 2: החלפת תווים לא רצויים ברווחים\n",
    "    cleaned = re.sub(tokenizer_re, \" \", lowercased)\n",
    "\n",
    "    # שלב 3: פיצול למילים (tokens)\n",
    "    tokens = cleaned.split()\n",
    "\n",
    "    # החזרת הרשימה הסופית של המילים\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:14.879167Z",
     "start_time": "2024-11-20T14:43:14.876377Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# For each document greate the tokenized representation of it\n",
    "l_doc1 = tokenize(doc1)\n",
    "l_doc2 = tokenize(doc2)\n",
    "l_doc3 = tokenize(doc3)\n",
    "l_doc4 = tokenize(doc4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:14.885805Z",
     "start_time": "2024-11-20T14:43:14.882936Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "['this', 'pasta', 'is', 'very', 'tasty', 'and', 'affordable']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the tokenization of the first document\n",
    "l_doc1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T18:25:50.427507Z",
     "start_time": "2024-11-20T18:25:50.413099Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BOW"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Extraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "SortedSet(['affordable', 'and', 'cheap', 'delicious', 'good', 'is', 'not', 'pasta', 'tastes', 'tasty', 'this', 'very'])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Create a Set of unique words per sentence ---\n",
    "# SortedSet is a data structure that maintains unique elements in sorted order.\n",
    "wordset = SortedSet()\n",
    "\n",
    "# Each of these lines adds the words from a list (like l_doc1, l_doc2, etc.) to wordset. Since wordset is a set, it will only keep unique words and discard any duplicates.\n",
    "wordset.update(l_doc1)\n",
    "wordset.update(l_doc2)\n",
    "wordset.update(l_doc3)\n",
    "wordset.update(l_doc4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:14.896896Z",
     "start_time": "2024-11-20T14:43:14.893650Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# --- Bag of Words Calculation ---\n",
    "# This function takes two arguments: wordset, a set of unique words, and l_doc, a list of words\n",
    "def calculate_bow(wordset, l_doc):\n",
    "    bow_dict = dict.fromkeys(wordset,0) # creates a dictionary\n",
    "    for word in l_doc: # iterates through each word\n",
    "        bow_dict[word]=l_doc.count(word) # For each word, this line counts its occurrences in l_doc and updates the corresponding entry in tf_diz\n",
    "    return bow_dict # The function returns the tf_diz dictionary, which now maps each word to its frequency in l_doc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:14.899104Z",
     "start_time": "2024-11-20T14:43:14.897374Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# --- Calculating Bag of Words for Documents ---\n",
    "# Each call generates a dictionary (e.g., bow1, bow2) where keys are words from wordset and values are their frequencies in the respective document.\n",
    "bow1 = calculate_bow(wordset, l_doc1)\n",
    "bow2 = calculate_bow(wordset, l_doc2)\n",
    "bow3 = calculate_bow(wordset, l_doc3)\n",
    "bow4 = calculate_bow(wordset, l_doc4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T21:22:34.217178Z",
     "start_time": "2024-11-20T21:22:34.210665Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BOW Calculation (pandas)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "   affordable  and  cheap  delicious  good  is  not  pasta  tastes  tasty  \\\n0           1    1      0          0     0   1    0      1       0      1   \n1           1    1      0          0     0   2    1      1       0      1   \n2           0    1      1          1     0   1    0      1       0      0   \n3           0    1      0          0     1   1    0      2       1      1   \n\n   this  very  \n0     1     1  \n1     1     0  \n2     1     0  \n3     0     0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>affordable</th>\n      <th>and</th>\n      <th>cheap</th>\n      <th>delicious</th>\n      <th>good</th>\n      <th>is</th>\n      <th>not</th>\n      <th>pasta</th>\n      <th>tastes</th>\n      <th>tasty</th>\n      <th>this</th>\n      <th>very</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Creating a DataFrame from BoW Data ---\n",
    "df_bow = pd.DataFrame([bow1, bow2, bow3, bow4])\n",
    "df_bow.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T21:22:43.446188Z",
     "start_time": "2024-11-20T21:22:43.434314Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BOW Calculation (sklearn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affordable' 'and' 'cheap' 'delicious' 'good' 'is' 'not' 'pasta' 'tastes'\n",
      " 'tasty' 'this' 'very']\n"
     ]
    }
   ],
   "source": [
    "# --- Converting wordset to CountVectorizer datatype ---\n",
    "# CountVectorizer is a popular tool in text analysis used to convert a collection of text documents into a matrix of token counts.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Converting wordset to CountVectorizer datatype\n",
    "vectorizer = CountVectorizer(vocabulary=wordset)\n",
    "print(vectorizer.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:20.909749Z",
     "start_time": "2024-11-20T14:43:18.346316Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   affordable  and  cheap  delicious  good  is  not  pasta  tastes  tasty  \\\n0           1    1      0          0     0   1    0      1       0      1   \n1           1    1      0          0     0   2    1      1       0      1   \n2           0    1      1          1     0   1    0      1       0      0   \n3           0    1      0          0     1   1    0      2       1      1   \n\n   this  very  \n0     1     1  \n1     1     0  \n2     1     0  \n3     0     0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>affordable</th>\n      <th>and</th>\n      <th>cheap</th>\n      <th>delicious</th>\n      <th>good</th>\n      <th>is</th>\n      <th>not</th>\n      <th>pasta</th>\n      <th>tastes</th>\n      <th>tasty</th>\n      <th>this</th>\n      <th>very</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit_transform is a method that performs two functions: fit and transform.\n",
    "# 1. Fit: identify all unique words in the documents\n",
    "# 2. Transform: Each row of this matrix corresponds to one of the documents. The value in each cell of the matrix is the count of how many times the corresponding word appears in the respective document.\n",
    "X = vectorizer.fit_transform([doc1,doc2,doc3,doc4])\n",
    "\n",
    "# Creating a DataFrame from the Matrix (More user-friendly)\n",
    "df_bow_sklearn = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "df_bow_sklearn.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:20.915778Z",
     "start_time": "2024-11-20T14:43:20.910729Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   affordable  and  cheap  delicious  good  is  not  pasta  tastes  tasty  \\\n0           1    1      0          0     0   1    0      1       0      1   \n1           1    1      0          0     0   2    1      1       0      1   \n2           0    1      1          1     0   1    0      1       0      0   \n3           0    1      0          0     1   1    0      2       1      1   \n\n   this  very  \n0     1     1  \n1     1     0  \n2     1     0  \n3     0     0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>affordable</th>\n      <th>and</th>\n      <th>cheap</th>\n      <th>delicious</th>\n      <th>good</th>\n      <th>is</th>\n      <th>not</th>\n      <th>pasta</th>\n      <th>tastes</th>\n      <th>tasty</th>\n      <th>this</th>\n      <th>very</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform([doc1,doc2,doc3,doc4])\n",
    "df_bow_sklearn = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "df_bow_sklearn.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:20.921213Z",
     "start_time": "2024-11-20T14:43:20.916536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   affordable  cheap  delicious  good  pasta  tastes  tasty\n0           1      0          0     0      1       0      1\n1           1      0          0     0      1       0      1\n2           0      1          1     0      1       0      0\n3           0      0          0     1      2       1      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>affordable</th>\n      <th>cheap</th>\n      <th>delicious</th>\n      <th>good</th>\n      <th>pasta</th>\n      <th>tastes</th>\n      <th>tasty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform([doc1,doc2,doc3,doc4])\n",
    "df_bow_sklearn = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "df_bow_sklearn.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:20.926617Z",
     "start_time": "2024-11-20T14:43:20.922315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   affordable  cheap  delicious  delicious cheap  pasta  pasta delicious  \\\n0           1      0          0                0      1                0   \n1           1      0          0                0      1                0   \n2           0      1          1                1      1                1   \n\n   pasta tasty  tasty  tasty affordable  \n0            1      1                 1  \n1            1      1                 1  \n2            0      0                 0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>affordable</th>\n      <th>cheap</th>\n      <th>delicious</th>\n      <th>delicious cheap</th>\n      <th>pasta</th>\n      <th>pasta delicious</th>\n      <th>pasta tasty</th>\n      <th>tasty</th>\n      <th>tasty affordable</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform([doc1,doc2,doc3])\n",
    "df_bow_sklearn = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "df_bow_sklearn.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:21.060886Z",
     "start_time": "2024-11-20T14:43:21.055710Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TFIDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "tfidf1 = \"This movie is very scary and long\"\n",
    "tfidf2 = \"This movie is not scary and is slow\"\n",
    "tfidf3 = \"This movie is spooky and good\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:22.687111Z",
     "start_time": "2024-11-20T14:43:22.680449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m vectorizer_tfidf \u001B[38;5;241m=\u001B[39m TfidfVectorizer(stop_words\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m'\u001B[39m, ngram_range\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m      3\u001B[0m X \u001B[38;5;241m=\u001B[39m vectorizer_tfidf\u001B[38;5;241m.\u001B[39mfit_transform([tfidf1, tfidf2, tfidf3])\n\u001B[0;32m----> 4\u001B[0m df_tfidf_sklearn \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(X\u001B[38;5;241m.\u001B[39mtoarray(), columns\u001B[38;5;241m=\u001B[39mvectorizer_tfidf\u001B[38;5;241m.\u001B[39mget_feature_names())\n\u001B[1;32m      5\u001B[0m df_tfidf_sklearn\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "X = vectorizer_tfidf.fit_transform([tfidf1, tfidf2, tfidf3])\n",
    "df_tfidf_sklearn = pd.DataFrame(X.toarray(), columns=vectorizer_tfidf.get_feature_names())\n",
    "df_tfidf_sklearn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T14:43:23.347728Z",
     "start_time": "2024-11-20T14:43:23.113400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
